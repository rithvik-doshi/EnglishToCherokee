{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5a5c282"
      },
      "source": [
        "# English to Cherokee"
      ],
      "id": "c5a5c282"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0c7b5ae"
      },
      "source": [
        "## Milestone Information"
      ],
      "id": "a0c7b5ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4df95152"
      },
      "source": [
        "### Team Members:\n",
        "Rithvik Doshi, Saisriram Gunturu, Ruihang (Henry) Liu"
      ],
      "id": "4df95152"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23e4dec0"
      },
      "source": [
        "### Project Description\n",
        "\n",
        "We aim to create a model to translate English text to Cherokee. We're hoping to come up with an approach to this problem since Cherokee is an endangered language, and we can use the models we learned about in class specifically regarding machine translation to see how well we can do."
      ],
      "id": "23e4dec0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6ba1ebd"
      },
      "source": [
        "### Approach\n",
        "We'll use the following data sources:\n",
        "- https://github.com/ZhangShiyue/ChrEn/tree/main/data\n",
        "- https://github.com/CherokeeLanguage/CherokeeEnglishCorpus/tree/master/corpus.aligned/en_chr\n",
        "\n",
        "Additionally, we will experiment with one of the following architectures/approaches to see what's the best way to translate from English to Cherokee:\n",
        "- https://github.com/lukysummer/Machine-Translation-Seq2Seq-Keras/tree/master/data\n",
        "- https://medium.com/@patrickhk/use-keras-to-build-a-english-to-french-translator-with-various-rnn-model-architecture-a374\n",
        "- https://github.com/LaurentVeyssier/Machine-translation-English-French-with-Deep-neural-Network/blob/main/machine_translation.ipynb\n",
        "- https://arxiv.org/pdf/2010.04791v1.pdf"
      ],
      "id": "c6ba1ebd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04930484"
      },
      "source": [
        "### Project Plan:\n",
        "\n",
        "The project will consist of the following phases:\n",
        "1. EDA / Data Loading\n",
        "    a. Concatenating as many data sources as possible to get as big of a corpus as we can\n",
        "    b. Split data into training, testing and validation sets\n",
        "2. Model Developemnt\n",
        "    a. Finalize Model Selection and Architecture and build in Pytorch\n",
        "3. Model Training\n",
        "    a. Use available SCC GPUs to train the model.\n",
        "4. Model Validation\n",
        "    a. Validation sentences should give us a metric of accuracy.\n",
        "5. Model Testing\n",
        "    a. Use ChrEn model to translate back to English to see how we did."
      ],
      "id": "04930484"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa3oeQERXS5d"
      },
      "source": [
        "Run the below cell in colab if first time running:"
      ],
      "id": "Wa3oeQERXS5d"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpx6ciFmXJ7A",
        "outputId": "d2fda881-bbfd-47f0-ad43-08b788e5a8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras) (0.1.8)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.23.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras --upgrade\n",
        "!pip install Keras-Preprocessing"
      ],
      "id": "qpx6ciFmXJ7A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1956ef3b"
      },
      "source": [
        "# EDA"
      ],
      "id": "1956ef3b"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaUbvfsk8kMC",
        "outputId": "07341a5b-9caa-4ebe-8c85-dcc44f1489e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "JaUbvfsk8kMC"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cfea1dfc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Senior/CS505/Project/corpus.aligned/en_chr\""
      ],
      "id": "cfea1dfc"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9679d7f7"
      },
      "outputs": [],
      "source": [
        "def load_input_for(language=\".en\"):\n",
        "    \"\"\"\n",
        "    Load the input for the given language\n",
        "    :param language: the language of the input (\".en\" for English and \".chr\" for Cherokee)\n",
        "    :return: the input\n",
        "    \"\"\"\n",
        "    # Get all .en files in the directory\n",
        "    file_list = [file for file in os.listdir(data_dir) if file.endswith(language)]\n",
        "\n",
        "    # Initialize the empty array for the input\n",
        "    lines_array = []    # structure: [lines in the document]\n",
        "\n",
        "    for file in file_list:\n",
        "        file_path = os.path.join(data_dir, file)\n",
        "        with open(file_path, \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                lines_array.append(line.strip())\n",
        "\n",
        "    return lines_array"
      ],
      "id": "9679d7f7"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bdeed1d9"
      },
      "outputs": [],
      "source": [
        "english_sentences = load_input_for(\".en\")\n",
        "cherokee_sentences = load_input_for(\".chr\")"
      ],
      "id": "bdeed1d9"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf995c85",
        "outputId": "30d39bf3-b23d-4e4a-8f7d-a1dc37dc5a6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107168 107168\n"
          ]
        }
      ],
      "source": [
        "print(len(english_sentences), len(cherokee_sentences))  # should match"
      ],
      "id": "cf995c85"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c40de23"
      },
      "source": [
        "## Data pre processing"
      ],
      "id": "2c40de23"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abb883c7"
      },
      "source": [
        "### Tokenizer:"
      ],
      "id": "abb883c7"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "24077a96"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.text import Tokenizer\n",
        "\n",
        "def tokenize(x):\n",
        "    x_tk = Tokenizer()\n",
        "    x_tk.fit_on_texts(x)\n",
        "    return x_tk.texts_to_sequences(x), x_tk"
      ],
      "id": "24077a96"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b760d484",
        "outputId": "defaf405-3d3b-4d05-ba1d-5af5c3dca358"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 1, 7, 3, 8, 1, 9, 2, 1, 10], [2, 3, 11, 12, 4, 13, 5, 2, 4, 14, 5]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Test our tokenize()\n",
        "test_text = [\"In the beginning God created the heavens and the earth.\",\n",
        "             \"And God said, Let there be light: and there was light.\"]  # just 2 short sentences from our data\n",
        "test_text_tokenized, test_tokenizer = tokenize(test_text)\n",
        "\n",
        "test_text_tokenized"
      ],
      "id": "b760d484"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "780c440e",
        "outputId": "1b9bb1d1-7653-4b01-8746-60f10aba4369"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'and': 2,\n",
              " 'god': 3,\n",
              " 'there': 4,\n",
              " 'light': 5,\n",
              " 'in': 6,\n",
              " 'beginning': 7,\n",
              " 'created': 8,\n",
              " 'heavens': 9,\n",
              " 'earth': 10,\n",
              " 'said': 11,\n",
              " 'let': 12,\n",
              " 'be': 13,\n",
              " 'was': 14}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "test_tokenizer.word_index"
      ],
      "id": "780c440e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fc5e561"
      },
      "source": [
        "We can see that keras has already taken into account of capital/lowercased letter and punctuations. So we don't have to.\n",
        "\n",
        "Apply tokenizer on our input data:"
      ],
      "id": "0fc5e561"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "e9647438"
      },
      "outputs": [],
      "source": [
        "english_sentences_tokenized, english_tokenizer = tokenize(english_sentences)\n",
        "cherokee_sentences_tokenized, cherokee_tokenizer = tokenize(cherokee_sentences)"
      ],
      "id": "e9647438"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93dfcfb3",
        "outputId": "221763f2-25dd-41cd-9c2e-9b7b61bd2bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocab size = 20763, Cherokee vocab size = 72759\n"
          ]
        }
      ],
      "source": [
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "cherokee_vocab_size = len(cherokee_tokenizer.word_index)\n",
        "print(\"English vocab size = {}, Cherokee vocab size = {}\".format(english_vocab_size, cherokee_vocab_size))"
      ],
      "id": "93dfcfb3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2ccc858"
      },
      "source": [
        "### Padding\n",
        "Truncate all sentences into equal length for our input: pad to the max length, leave trailing 0 (post)"
      ],
      "id": "b2ccc858"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6fb2af04"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "def pad(x):\n",
        "    length = max([len(sentence) for sentence in x])\n",
        "    return pad_sequences(x, maxlen=length, padding='post')"
      ],
      "id": "6fb2af04"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d780f3bb",
        "outputId": "f0c72591-e876-4f31-86a3-3bb920b4447a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  1,  7,  3,  8,  1,  9,  2,  1, 10,  0],\n",
              "       [ 2,  3, 11, 12,  4, 13,  5,  2,  4, 14,  5]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# testing padding function:\n",
        "test_text_padded = pad(test_text_tokenized)\n",
        "test_text_padded"
      ],
      "id": "d780f3bb"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dcb4b1f9"
      },
      "outputs": [],
      "source": [
        "# Apply padding to input:\n",
        "english_sentences_padded = pad(english_sentences_tokenized)\n",
        "cherokee_sentences_padded = pad(cherokee_sentences_tokenized)"
      ],
      "id": "dcb4b1f9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfe00149"
      },
      "source": [
        "### Write function to map logits back to token label\n",
        "Function to convert predictions (a bunch of probability) back to sentence"
      ],
      "id": "cfe00149"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "68de85c3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def logits_to_text(logits, tokenizer):\n",
        "    idx_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    idx_to_words[0] = '<PAD>'\n",
        "    return ' '.join([idx_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ],
      "id": "68de85c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0944ff76"
      },
      "source": [
        "### Make Dataloader"
      ],
      "id": "0944ff76"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f73b7751"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Basic_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, X,Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    # return a pair x,y at the index idx in the data set\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n"
      ],
      "id": "f73b7751"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "d7251741"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(english_sentences_padded, cherokee_sentences_padded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the train data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = Basic_Dataset(X_train, y_train)\n",
        "val_dataset = Basic_Dataset(X_val, y_val)\n",
        "test_dataset = Basic_Dataset(X_test, y_test)"
      ],
      "id": "d7251741"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "20409b7d"
      },
      "outputs": [],
      "source": [
        "# For torch models:\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Or a loader with all data:\n",
        "all_loader = DataLoader(Basic_Dataset(english_sentences_padded, cherokee_sentences_padded), batch_size=batch_size, shuffle=True)"
      ],
      "id": "20409b7d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e328c6a"
      },
      "source": [
        "# First model (Simple RNN, not working neither locally or on colab):"
      ],
      "id": "8e328c6a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98f224e5",
        "outputId": "28d0c9fc-971b-4a6c-a645-88eced8deda7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "68587 68587\n",
            "17147 17147\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train), len(y_train))\n",
        "print(len(X_val), len(y_val))"
      ],
      "id": "98f224e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "332f0a91",
        "outputId": "b48527d2-c3a0-4598-b203-9ba1c88daec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3980f73fc347>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     ]\n\u001b[0;32m---> 60\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-21-3980f73fc347>\", line 14, in <cell line: 14>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1783, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1377, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1360, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1349, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1127, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1185, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5777, in sparse_categorical_crossentropy\n\nlogits and labels must have the same first dimension, got logits shape [32,72759] and labels shape [26432]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_3343]"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=english_vocab_size, output_dim=100, input_length=None))\n",
        "model.add(LSTM(units=128))\n",
        "model.add(Dense(units=cherokee_vocab_size, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "id": "332f0a91"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578ea3d9"
      },
      "source": [
        "# Second model:"
      ],
      "id": "578ea3d9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e5cd44e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        embedded = self.embedding(input_seq)\n",
        "        packed = pack_padded_sequence(embedded, input_lengths)\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        outputs, _ = pad_packed_sequence(outputs)\n",
        "        return outputs, hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        embedded = self.embedding(input_seq)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, target_seq, teacher_forcing_ratio=0.5):\n",
        "        batch_size = input_seq.size(0)\n",
        "        target_length = target_seq.size(1)\n",
        "        target_vocab_size = self.decoder.out.out_features\n",
        "\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_lengths)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]] * batch_size, device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "        if use_teacher_forcing:\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "                decoder_input = target_seq[:, di]\n",
        "        else:\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoder_output\n",
        "\n",
        "# Define hyperparameters\n",
        "input_size = len(english_tokenizer.word_index) + 1\n",
        "output_size = len(cherokee_tokenizer.word_index) + 1\n",
        "hidden_size = 256\n",
        "num_layers = 2\n",
        "\n",
        "# Create encoder and decoder instances\n",
        "encoder = Encoder(input_size, hidden_size, num_layers)\n",
        "decoder = Decoder(hidden_size, output_size, num_layers)\n",
        "\n",
        "# Create the Seq2Seq model\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "id": "6e5cd44e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "184384eb",
        "outputId": "47613a55-f4bc-4f03-e397-5e4134ae5b13"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected `len(lengths)` to be equal to batch_size, but got 128 (batch_size=1266)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb Cell 32\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m output \u001b[39m=\u001b[39m model(input_seq, input_lengths, target_seq)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Compute the loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, output_size), target_seq\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32m/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb Cell 32\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m target_length \u001b[39m=\u001b[39m target_seq\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m target_vocab_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mout\u001b[39m.\u001b[39mout_features\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m encoder_outputs, encoder_hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(input_seq, input_lengths)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m decoder_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[SOS_token]] \u001b[39m*\u001b[39m batch_size, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m decoder_hidden \u001b[39m=\u001b[39m encoder_hidden\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "\u001b[1;32m/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_seq, input_lengths, hidden\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(input_seq)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     packed \u001b[39m=\u001b[39m pack_padded_sequence(embedded, input_lengths)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     outputs, hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru(packed, hidden)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/henryliu/Downloads/EnglishToCherokee/EnglishtoCherokee.ipynb#X56sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     outputs, _ \u001b[39m=\u001b[39m pad_packed_sequence(outputs)\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/utils/rnn.py:262\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    258\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m batch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    259\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mindex_select(batch_dim, sorted_indices)\n\u001b[1;32m    261\u001b[0m data, batch_sizes \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> 262\u001b[0m     _VF\u001b[39m.\u001b[39;49m_pack_padded_sequence(\u001b[39minput\u001b[39;49m, lengths, batch_first)\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m _packed_sequence_init(data, batch_sizes, sorted_indices, \u001b[39mNone\u001b[39;00m)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected `len(lengths)` to be equal to batch_size, but got 128 (batch_size=1266)"
          ]
        }
      ],
      "source": [
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    # Set the model to train mode\n",
        "    model.train()\n",
        "\n",
        "    # Iterate over the training data\n",
        "    for input_seq, target_seq in train_loader:\n",
        "        # Move the input and target sequences to the device\n",
        "        input_seq = input_seq.to(device)\n",
        "        target_seq = target_seq.to(device)\n",
        "\n",
        "        # Get the input sequence lengths\n",
        "        input_lengths = torch.sum(input_seq != 0, dim=1)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_seq, input_lengths, target_seq)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(output.view(-1, output_size), target_seq.view(-1))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the total loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print the average loss for the epoch\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
      ],
      "id": "184384eb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W7Mko_h8zSp"
      },
      "source": [
        "# Sequence to Sequence Translator"
      ],
      "id": "2W7Mko_h8zSp"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h4Qvk3C_85uY"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.layers import TextVectorization\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "h4Qvk3C_85uY"
    },
    {
      "cell_type": "code",
      "source": [
        "eng_len = [len(sentence) for sentence in english_sentences]\n",
        "print(max(eng_len), min(eng_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0C9bAh4IAOO",
        "outputId": "a6b972ca-5f7c-4ac1-d2b4-6a3b990829ec"
      },
      "id": "E0C9bAh4IAOO",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7287 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "che_len = [len(sentence) for sentence in cherokee_sentences]\n",
        "print(max(che_len), min(che_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eGEDzWZIZRb",
        "outputId": "91b66f12-edd2-4571-edd4-c0f5bcf2d2ff"
      },
      "id": "4eGEDzWZIZRb",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4846 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8i3A5_Y9BwK",
        "outputId": "91ec86f7-9777-4457-8044-b1b9705125e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107168 total pairs\n",
            "68587 training pairs\n",
            "17147 validation pairs\n",
            "21434 test pairs\n"
          ]
        }
      ],
      "source": [
        "# make text_pair and prepend the token \"[start]\" and postpend \"[end]\" to cherokee_sentences\n",
        "text_pair = []\n",
        "for i in range(len(english_sentences)):\n",
        "    text_pair.append([english_sentences[i], \"[start] \" + cherokee_sentences[i] + \" [end]\"])\n",
        "\n",
        "# split the sentence pairs into a training set, a validation set, and a test set.\n",
        "train_pairs, test_pairs = train_test_split(text_pair, test_size=0.2, random_state=42)\n",
        "train_pairs, val_pairs = train_test_split(train_pairs, test_size=0.2, random_state=42)\n",
        "print(f\"{len(text_pair)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "id": "p8i3A5_Y9BwK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IH-rYGXGGH8"
      },
      "source": [
        "## Vectorizing the text data\n",
        "\n",
        "use 2 TextVectorization layers to vectorize the text data (1 for English, 1 for Cherokee)"
      ],
      "id": "_IH-rYGXGGH8"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "kDCYq37--JHD"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "strip_chars = string.punctuation\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = max(english_vocab_size, cherokee_vocab_size)\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    return tf_strings.regex_replace(input_string, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "che_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    # standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_che_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "che_vectorization.adapt(train_che_texts)"
      ],
      "id": "kDCYq37--JHD"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tmzqTif5J0ZF"
      },
      "id": "tmzqTif5J0ZF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage: transforming a single sentence\n",
        "sample_eng_sentence = train_eng_texts[0]\n",
        "sample_che_sentence = train_che_texts[0]\n",
        "\n",
        "# Applying the vectorization to the sample sentences\n",
        "eng_vectorized = eng_vectorization([sample_eng_sentence])\n",
        "che_vectorized = che_vectorization([sample_che_sentence])\n",
        "\n",
        "# Displaying the results\n",
        "print(sample_eng_sentence)\n",
        "print(\"English vectorized:\", eng_vectorized)\n",
        "print()\n",
        "print(sample_che_sentence)\n",
        "print(\"Chechen vectorized:\", che_vectorized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULMkn8qaJRJN",
        "outputId": "e40a39bb-38d8-4f8c-cbd1-bcb66bf4e666"
      },
      "id": "ULMkn8qaJRJN",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And Simon himself had faith and, having had baptism, he went with Philip and, seeing the signs and the great wonders which he did, he was full of surprise.\n",
            "English vectorized: tf.Tensor(\n",
            "[[  3 425 137  50 140   3  73  50 737   9  55  22 741   3 360   2 566   3\n",
            "    2 114]], shape=(1, 20), dtype=int64)\n",
            "\n",
            "[start]   ,   ;     , . [end]\n",
            "Chechen vectorized: tf.Tensor(\n",
            "[[    2  1206    14 11149 24367 29106   572 30943   186     4   378   533\n",
            "  30644     3     0     0     0     0     0     0     0]], shape=(1, 21), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_q9d0hUGvlR"
      },
      "source": [
        "Now, format the datasets\n",
        "\n",
        "At each training step, the model will predict target word N + 1 using the source sentence and the target words 0 to N.\n",
        "\n",
        "Thus, the training dataset will yield (`inputs`, `targets`) where:\n",
        "* `inputs` - a dictionary with 2 keys:\n",
        "    - `encoder_inputs` - vectorized source sentence.\n",
        "    - `decoder_inputs` - the target sentence so far (words 0 to N used to predict the words 0 to N + 1)\n",
        "* `targets` - target sentence offset by 1 step - provides the next words in the target sentence  what the model will try to predict"
      ],
      "id": "L_q9d0hUGvlR"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "HT7H8r4EGJPE"
      },
      "outputs": [],
      "source": [
        "def format_dataset(eng, che):\n",
        "    eng = eng_vectorization(eng)\n",
        "    che = che_vectorization(che)\n",
        "\n",
        "    inputs = {\n",
        "        \"encoder_inputs\": eng,\n",
        "        \"decoder_inputs\": che[:, :-1],\n",
        "    }\n",
        "\n",
        "    return (inputs, che[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, che_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    che_texts = list(che_texts)\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, che_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "id": "HT7H8r4EGJPE"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8oNJPLuJelm",
        "outputId": "881ab869-a8b4-435d-c1e5-6a1a89750872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "id": "x8oNJPLuJelm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0tF7sSlJl29"
      },
      "source": [
        "## Building the model:\n"
      ],
      "id": "H0tF7sSlJl29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3h9VoTLJyV8"
      },
      "source": [
        "Our sequence-to-sequence Transformer consists of a TransformerEncoder and a TransformerDecoder chained together. To make the model aware of word order, we also use a PositionalEmbedding layer.\n",
        "\n",
        "source sequence --> `TransformerEncoder` (output a new representation of the source) --> pass the new representation with the target sequence so far (target words 0 to N) to `TransformerDecoder` --> predict the next words in the target sequence (N + 1 and beyond)\n",
        "\n",
        "Layers adapted from https://keras.io/examples/nlp/neural_machine_translation_with_transformer/"
      ],
      "id": "h3h9VoTLJyV8"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "qxtn1tDJKqnP"
      },
      "outputs": [],
      "source": [
        "import keras.ops as ops"
      ],
      "id": "qxtn1tDJKqnP"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "fj74oiBjJjMw"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "id": "fj74oiBjJjMw"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "4MouDVIVK4q-"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "            padding_mask = ops.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = ops.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = ops.arange(sequence_length)[:, None]\n",
        "        j = ops.arange(sequence_length)\n",
        "        mask = ops.cast(i >= j, dtype=\"int32\")\n",
        "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = ops.concatenate(\n",
        "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
        "            axis=0,\n",
        "        )\n",
        "        return ops.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "id": "4MouDVIVK4q-"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Pi_mpDsTKz0_"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = ops.shape(inputs)[-1]\n",
        "        positions = ops.arange(0, length, 1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        if mask is None:\n",
        "            return None\n",
        "        else:\n",
        "            return ops.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config\n"
      ],
      "id": "Pi_mpDsTKz0_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OobIcMbNLBp-"
      },
      "source": [
        "Assemble the end-to-end model:"
      ],
      "id": "OobIcMbNLBp-"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "b2oYgucPK7dh"
      },
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "id": "b2oYgucPK7dh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39C7a4PoLT5J"
      },
      "source": [
        "## Training our model"
      ],
      "id": "39C7a4PoLT5J"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "GmRaoPbfLQ88",
        "outputId": "c3e8fc3d-87b4-4466-d97c-2d1b0ad7f205"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " encoder_inputs             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  -                          \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                                              \n",
              "\n",
              " positional_embedding_6     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       \u001b[38;5;34m18,631,424\u001b[0m  encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mPositionalEmbedding\u001b[0m)                                                                     \n",
              "\n",
              " decoder_inputs             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                     \u001b[38;5;34m0\u001b[0m  -                          \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                                              \n",
              "\n",
              " transformer_encoder_3      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)        \u001b[38;5;34m3,155,456\u001b[0m  positional_embedding_6[\u001b[38;5;34m0\u001b[0m] \n",
              " (\u001b[38;5;33mTransformerEncoder\u001b[0m)                                                                      \n",
              "\n",
              " functional_23              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72759\u001b[0m)     \u001b[38;5;34m42,590,007\u001b[0m  decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      \n",
              " (\u001b[38;5;33mFunctional\u001b[0m)                                                   transformer_encoder_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)              </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to               </span>\n",
              "\n",
              " encoder_inputs             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                                              \n",
              "\n",
              " positional_embedding_6     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       <span style=\"color: #00af00; text-decoration-color: #00af00\">18,631,424</span>  encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)                                                                     \n",
              "\n",
              " decoder_inputs             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                          \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                                              \n",
              "\n",
              " transformer_encoder_3      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span>  positional_embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)                                                                      \n",
              "\n",
              " functional_23              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72759</span>)     <span style=\"color: #00af00; text-decoration-color: #00af00\">42,590,007</span>  decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                                                   transformer_encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64,376,887\u001b[0m (245.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,376,887</span> (245.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m64,376,887\u001b[0m (245.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,376,887</span> (245.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 155ms/step - accuracy: 0.5948 - loss: 3.9290 - val_accuracy: 0.6382 - val_loss: 2.9643\n",
            "Epoch 2/3\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 125ms/step - accuracy: 0.6444 - loss: 2.8524 - val_accuracy: 0.6618 - val_loss: 2.5849\n",
            "Epoch 3/3\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 124ms/step - accuracy: 0.6713 - loss: 2.4446 - val_accuracy: 0.6966 - val_loss: 2.2292\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e4f89b93dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "epochs = 3  # 1 for testing\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "id": "GmRaoPbfLQ88"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model for later evaluation"
      ],
      "metadata": {
        "id": "NsJPzgdlq0Sf"
      },
      "id": "NsJPzgdlq0Sf"
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.save(\"sequence_to_sequence_3.keras\")"
      ],
      "metadata": {
        "id": "5V8VQD-1qzSO"
      },
      "id": "5V8VQD-1qzSO",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcrT08UILl_O"
      },
      "source": [
        "## Decoding test sentences"
      ],
      "id": "GcrT08UILl_O"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "fEdBAfZ9Ld8e"
      },
      "outputs": [],
      "source": [
        "che_vocab = che_vectorization.get_vocabulary()\n",
        "che_index_lookup = dict(zip(range(len(che_vocab)), che_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = che_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n",
        "        sampled_token_index = ops.convert_to_numpy(\n",
        "            ops.argmax(predictions[0, i, :])\n",
        "        ).item(0)\n",
        "        sampled_token = che_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence"
      ],
      "id": "fEdBAfZ9Ld8e"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "K_inr8toXCuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e61a5e-bb31-4ed4-ec0c-7f345096aea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input = had an itch..   Translated = [start]                    end\n",
            "Input = 'And it cometh to pass, that we have come up unto thy servant my father, that we declare to him the words of my lord;.   Translated = [start]                    end\n",
            "Input = Later..   Translated = [start]                    end\n",
            "Input = bless those cursing you, and pray for those accusing you falsely;.   Translated = [start]                    end\n",
            "Input = And the Lord said, If ye had faith as a grain of mustard-seed, ye might say to this sycamine-tree, Be thou plucked up by the root, and be thou planted in the sea; and it would obey you..   Translated = [start]                    end\n",
            "Input = Of the men therefore that have companied with us all the time that the Lord Jesus went in and went out among us,.   Translated = [start]                    end\n",
            "Input = crawls..   Translated = [start]                    end\n",
            "Input = and the other disciples came in the small boat, for they were not far from the land, but somewhere about two hundred cubits, dragging the net of fishes..   Translated = [start]                    end\n",
            "Input = In like manner also, that women adorn themselves in decent apparel, with modesty and sobriety; not with broidered hair, or gold, or pearls, or costly array,.   Translated = [start]                    end\n",
            "Input = Often floating..   Translated = [start]                    end\n",
            "Input = So that in him you have wealth in all things, in word and in knowledge of every sort;.   Translated = [start]                    end\n",
            "Input = Going to be from..   Translated = [start]                    end\n",
            "Input = Just now went to be a light going out..   Translated = [start]                    end\n",
            "Input = Washes it..   Translated = [start]                    end\n",
            "Input = And he cried and said, Father Abraham, have mercy on me, and send Lazarus, that he may dip the tip of his finger in water, and cool my tongue; for I am in anguish in this flame..   Translated = [start]                    end\n",
            "Input = Likewise, ye younger, submit yourselves to the elder. Yes, all of you be subject one to another, and be clothed with humility: for God resisteth the proud, and giveth grace to the humble..   Translated = [start]                    end\n",
            "Input = Let come to be burying it..   Translated = [start]                    end\n",
            "Input = Chapter 4.   Translated = [start]                    end\n",
            "Input = Quench not the Spirit;.   Translated = [start]                    end\n",
            "Input = and God, what things before He had declared through the mouth of all His prophets, that the Christ should suffer, He did thus fulfil;.   Translated = [start]                    end\n",
            "Input = Wives, be subject to your own husbands, as to the Lord..   Translated = [start]                    end\n",
            "Input = Then said Jesus unto them, I will question you something: Is it lawful on the sabbaths to do good, or to do evil? life to save or to kill?.   Translated = [start]                    end\n",
            "Input = God that made the world, and all things therein, seeing that he is Lord of heaven and earth, dwelleth not in temples made with hands;.   Translated = [start]                    end\n",
            "Input = And he got into a boat and went across and came to his town..   Translated = [start]                    end\n",
            "Input = and crying out with a loud voice, he said, \"What have I to do with you, Jesus, you Son of the Most High God? I adjure you by God, don't torment me.\".   Translated = [start]                    end\n",
            "Input = Often cutting off it..   Translated = [start]                    end\n",
            "Input = And his sisters, are they not all with us? from where, then, has he all these things?.   Translated = [start]                    end\n",
            "Input = And he called unto him the multitude with his disciples, and said unto them, If any man would come after me, let him deny himself, and take up his cross, and follow me..   Translated = [start]                    end\n",
            "Input = And God saith, 'Let the earth bring forth the living creature after its kind, cattle and creeping thing, and beast of the earth after its kind:' and it is so..   Translated = [start]                    end\n",
            "Input = Recently was planning to..   Translated = [start]                    end\n"
          ]
        }
      ],
      "source": [
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(30):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "\n",
        "    print(f\"Input = {input_sentence}   Translated = {translated}\")"
      ],
      "id": "K_inr8toXCuT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBch0CIVwW_7"
      },
      "outputs": [],
      "source": [],
      "id": "yBch0CIVwW_7"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8e328c6a",
        "578ea3d9"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}