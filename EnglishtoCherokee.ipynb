{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5a5c282"
      },
      "source": [
        "# English to Cherokee"
      ],
      "id": "c5a5c282"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstract"
      ],
      "metadata": {
        "id": "FIll75MXT_AV"
      },
      "id": "FIll75MXT_AV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wanted to approach creating an English to Cherokee model based on NLP techniques. Cherokee, or Tsalagi, is an endangered-to-moribund Iroquoian language and the native language of the Cherokee people. As the number of speakers of this language is in decline, we wanted to create a model that would help to easily translate between the two languages. Notice that Cherokee is written in a different syllabary than English (ᏣᎳᎩ ᎦᏬᏂᎯᏍᏗ), this syllabary was invented by Sequoyah in the 1810s and 1820s. The characters used to represent the Cherokee language are covered by the Unicode blocks U+13A0 to U+13FF (uppercase letters + six lowercase letters) and U+AB70 to U+ABBF (the rest of the lowercase letters).\n",
        "\n",
        "To this end, our group took three approaches to this model. After creating a dataloader for English and Cherokee sentences, we created three models: A simple RNN, an encoder-decoder model and a transformer model. While we were unable to troubleshoot the first and second models to get them fully functioning, we were able to get the third model to work and produce Cherokee sentences as output to English input."
      ],
      "metadata": {
        "id": "PU59vVc0toNH"
      },
      "id": "PU59vVc0toNH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0c7b5ae"
      },
      "source": [
        "## Milestone Information"
      ],
      "id": "a0c7b5ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4df95152"
      },
      "source": [
        "### Team Members:\n",
        "Rithvik Doshi, Saisriram Gunturu, Ruihang Liu"
      ],
      "id": "4df95152"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23e4dec0"
      },
      "source": [
        "### Project Description\n",
        "\n",
        "We aim to create a model to translate English text to Cherokee. We're hoping to come up with an approach to this problem since Cherokee is an endangered language, and we can use the models we learned about in class specifically regarding machine translation to see how well we can do."
      ],
      "id": "23e4dec0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6ba1ebd"
      },
      "source": [
        "### Approach\n",
        "We'll use the following data sources:\n",
        "- https://github.com/ZhangShiyue/ChrEn/tree/main/data\n",
        "- https://github.com/CherokeeLanguage/CherokeeEnglishCorpus/tree/master/corpus.aligned/en_chr\n",
        "\n",
        "Additionally, we will experiment with one of the following architectures/approaches to see what's the best way to translate from English to Cherokee:\n",
        "- https://github.com/lukysummer/Machine-Translation-Seq2Seq-Keras/tree/master/data\n",
        "- https://medium.com/@patrickhk/use-keras-to-build-a-english-to-french-translator-with-various-rnn-model-architecture-a374\n",
        "- https://github.com/LaurentVeyssier/Machine-translation-English-French-with-Deep-neural-Network/blob/main/machine_translation.ipynb\n",
        "- https://arxiv.org/pdf/2010.04791v1.pdf"
      ],
      "id": "c6ba1ebd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04930484"
      },
      "source": [
        "### Project Plan:\n",
        "\n",
        "The project will consist of the following phases:\n",
        "1. EDA / Data Loading\n",
        "\n",
        "    a. Concatenating as many data sources as possible to get as big of a corpus as we can\n",
        "\n",
        "    b. Split data into training, testing and validation sets\n",
        "2. Model Developemnt\n",
        "\n",
        "    a. Finalize Model Selection and Architecture and build in Pytorch\n",
        "    \n",
        "3. Model Training"
      ],
      "id": "04930484"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa3oeQERXS5d"
      },
      "source": [
        "Run the below cell in colab if first time running:"
      ],
      "id": "Wa3oeQERXS5d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpx6ciFmXJ7A",
        "outputId": "9c1238b2-4233-4a96-8fd6-2e24611b2d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.23.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.9.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras) (0.1.8)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.23.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras --upgrade\n",
        "!pip install Keras-Preprocessing"
      ],
      "id": "qpx6ciFmXJ7A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1956ef3b"
      },
      "source": [
        "# EDA"
      ],
      "id": "1956ef3b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaUbvfsk8kMC",
        "outputId": "7e018bed-23a6-4254-99f2-fe7eb94e0956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "JaUbvfsk8kMC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfea1dfc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/Senior/CS505/Project/corpus.aligned/en_chr\" # for Ruihang\n",
        "# data_dir = \"/content/drive/MyDrive/Colab Notebooks/corpus.aligned/en_chr\""
      ],
      "id": "cfea1dfc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9679d7f7"
      },
      "outputs": [],
      "source": [
        "def load_input_for(language=\".en\"):\n",
        "    \"\"\"\n",
        "    Load the input for the given language\n",
        "    :param language: the language of the input (\".en\" for English and \".chr\" for Cherokee)\n",
        "    :return: the input\n",
        "    \"\"\"\n",
        "    # Get all .en files in the directory\n",
        "    file_list = [file for file in os.listdir(data_dir) if file.endswith(language)]\n",
        "\n",
        "    # Initialize the empty array for the input\n",
        "    lines_array = []    # structure: [lines in the document]\n",
        "\n",
        "    for file in file_list:\n",
        "        file_path = os.path.join(data_dir, file)\n",
        "        with open(file_path, \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                lines_array.append(line.strip())\n",
        "\n",
        "    return lines_array"
      ],
      "id": "9679d7f7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdeed1d9"
      },
      "outputs": [],
      "source": [
        "english_sentences = load_input_for(\".en\")\n",
        "cherokee_sentences = load_input_for(\".chr\")"
      ],
      "id": "bdeed1d9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf995c85",
        "outputId": "6d225d29-1288-4f42-97da-bfe9f2541548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107168 107168\n"
          ]
        }
      ],
      "source": [
        "print(len(english_sentences), len(cherokee_sentences))  # should match"
      ],
      "id": "cf995c85"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c40de23"
      },
      "source": [
        "## Data pre processing"
      ],
      "id": "2c40de23"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abb883c7"
      },
      "source": [
        "### Tokenizer:"
      ],
      "id": "abb883c7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24077a96"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.text import Tokenizer\n",
        "\n",
        "def tokenize(x):\n",
        "    x_tk = Tokenizer()\n",
        "    x_tk.fit_on_texts(x)\n",
        "    return x_tk.texts_to_sequences(x), x_tk"
      ],
      "id": "24077a96"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b760d484",
        "outputId": "70321433-f99f-4855-db98-37f969de5a71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 1, 7, 3, 8, 1, 9, 2, 1, 10], [2, 3, 11, 12, 4, 13, 5, 2, 4, 14, 5]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Test our tokenize()\n",
        "test_text = [\"In the beginning God created the heavens and the earth.\",\n",
        "             \"And God said, Let there be light: and there was light.\"]  # just 2 short sentences from our data\n",
        "test_text_tokenized, test_tokenizer = tokenize(test_text)\n",
        "\n",
        "test_text_tokenized"
      ],
      "id": "b760d484"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "780c440e",
        "outputId": "7b62f6a2-b8f7-41fa-9219-5eae3326858c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'and': 2,\n",
              " 'god': 3,\n",
              " 'there': 4,\n",
              " 'light': 5,\n",
              " 'in': 6,\n",
              " 'beginning': 7,\n",
              " 'created': 8,\n",
              " 'heavens': 9,\n",
              " 'earth': 10,\n",
              " 'said': 11,\n",
              " 'let': 12,\n",
              " 'be': 13,\n",
              " 'was': 14}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "test_tokenizer.word_index"
      ],
      "id": "780c440e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fc5e561"
      },
      "source": [
        "We can see that keras has already taken into account of capital/lowercased letter and punctuations. So we don't have to.\n",
        "\n",
        "Apply tokenizer on our input data:"
      ],
      "id": "0fc5e561"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9647438"
      },
      "outputs": [],
      "source": [
        "english_sentences_tokenized, english_tokenizer = tokenize(english_sentences)\n",
        "cherokee_sentences_tokenized, cherokee_tokenizer = tokenize(cherokee_sentences)"
      ],
      "id": "e9647438"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93dfcfb3",
        "outputId": "14cfeb18-f354-4277-9810-d6ec06e9cc79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English vocab size = 20763, Cherokee vocab size = 72759\n"
          ]
        }
      ],
      "source": [
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "cherokee_vocab_size = len(cherokee_tokenizer.word_index)\n",
        "print(\"English vocab size = {}, Cherokee vocab size = {}\".format(english_vocab_size, cherokee_vocab_size))"
      ],
      "id": "93dfcfb3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2ccc858"
      },
      "source": [
        "### Padding\n",
        "Truncate all sentences into equal length for our input: pad to the max length, leave trailing 0 (post)"
      ],
      "id": "b2ccc858"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fb2af04"
      },
      "outputs": [],
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "def pad(x):\n",
        "    length = max([len(sentence) for sentence in x])\n",
        "    return pad_sequences(x, maxlen=length, padding='post')"
      ],
      "id": "6fb2af04"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d780f3bb",
        "outputId": "7d1f12d8-944a-45eb-f7ae-c10e92e8cc8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  1,  7,  3,  8,  1,  9,  2,  1, 10,  0],\n",
              "       [ 2,  3, 11, 12,  4, 13,  5,  2,  4, 14,  5]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# testing padding function:\n",
        "test_text_padded = pad(test_text_tokenized)\n",
        "test_text_padded"
      ],
      "id": "d780f3bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcb4b1f9"
      },
      "outputs": [],
      "source": [
        "# Apply padding to input:\n",
        "english_sentences_padded = pad(english_sentences_tokenized)\n",
        "cherokee_sentences_padded = pad(cherokee_sentences_tokenized)"
      ],
      "id": "dcb4b1f9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfe00149"
      },
      "source": [
        "### Write function to map logits back to token label\n",
        "Function to convert predictions (a bunch of probability) back to sentence"
      ],
      "id": "cfe00149"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68de85c3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def logits_to_text(logits, tokenizer):\n",
        "    idx_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    idx_to_words[0] = '<PAD>'\n",
        "    return ' '.join([idx_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ],
      "id": "68de85c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0944ff76"
      },
      "source": [
        "### Make Dataloader"
      ],
      "id": "0944ff76"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f73b7751"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Basic_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, X,Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    # return a pair x,y at the index idx in the data set\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n"
      ],
      "id": "f73b7751"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7251741"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(english_sentences_padded, cherokee_sentences_padded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the train data into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = Basic_Dataset(X_train, y_train)\n",
        "val_dataset = Basic_Dataset(X_val, y_val)\n",
        "test_dataset = Basic_Dataset(X_test, y_test)"
      ],
      "id": "d7251741"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20409b7d"
      },
      "outputs": [],
      "source": [
        "# For torch models:\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Or a loader with all data:\n",
        "all_loader = DataLoader(Basic_Dataset(english_sentences_padded, cherokee_sentences_padded), batch_size=batch_size, shuffle=True)"
      ],
      "id": "20409b7d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e328c6a"
      },
      "source": [
        "# First model (Simple RNN, not working neither locally or on colab):"
      ],
      "id": "8e328c6a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98f224e5",
        "outputId": "f56ca14a-824d-435a-a4cc-e460f2552c09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68587 68587\n",
            "17147 17147\n"
          ]
        }
      ],
      "source": [
        "print(len(X_train), len(y_train))\n",
        "print(len(X_val), len(y_val))"
      ],
      "id": "98f224e5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "332f0a91",
        "outputId": "76bd5599-5945-4771-e160-904ca776a3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c91d2eded170>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/nn.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;34m\"Argument `output` must have rank (ndim) `target.ndim - 1`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;34m\"Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Argument `output` must have rank (ndim) `target.ndim - 1`. Received: target.shape=(None, 826), output.shape=(None, 72759)"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=english_vocab_size, output_dim=100))\n",
        "model.add(LSTM(units=128))\n",
        "model.add(Dense(units=cherokee_vocab_size, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "id": "332f0a91"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "578ea3d9"
      },
      "source": [
        "# Second model:"
      ],
      "id": "578ea3d9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e5cd44e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        embedded = self.embedding(input_seq)\n",
        "        packed = pack_padded_sequence(embedded, input_lengths)\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        outputs, _ = pad_packed_sequence(outputs)\n",
        "        return outputs, hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        embedded = self.embedding(input_seq)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, target_seq, teacher_forcing_ratio=0.5):\n",
        "        batch_size = input_seq.size(0)\n",
        "        target_length = target_seq.size(1)\n",
        "        target_vocab_size = self.decoder.out.out_features\n",
        "\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_lengths)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]] * batch_size, device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "        if use_teacher_forcing:\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "                decoder_input = target_seq[:, di]\n",
        "        else:\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoder_output\n",
        "\n",
        "# Define hyperparameters\n",
        "input_size = len(english_tokenizer.word_index) + 1\n",
        "output_size = len(cherokee_tokenizer.word_index) + 1\n",
        "hidden_size = 256\n",
        "num_layers = 2\n",
        "\n",
        "# Create encoder and decoder instances\n",
        "encoder = Encoder(input_size, hidden_size, num_layers)\n",
        "decoder = Decoder(hidden_size, output_size, num_layers)\n",
        "\n",
        "# Create the Seq2Seq model\n",
        "model = Seq2Seq(encoder, decoder)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "id": "6e5cd44e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "184384eb",
        "outputId": "54221662-d96d-484d-8b62-610651eaa2cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-0209609a0869>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-5b956cdfa6a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq, input_lengths, target_seq, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtarget_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSOS_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-5b956cdfa6a0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_seq, input_lengths, hidden)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_packed_sequence_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected `len(lengths)` to be equal to batch_size, but got 128 (batch_size=1266)"
          ]
        }
      ],
      "source": [
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    # Set the model to train mode\n",
        "    model.train()\n",
        "\n",
        "    # Iterate over the training data\n",
        "    for input_seq, target_seq in train_loader:\n",
        "        # Get the input sequence lengths\n",
        "        input_lengths = torch.sum(input_seq != 0, dim=1)\n",
        "\n",
        "        # Move the input and target sequences to the device\n",
        "        input_seq = input_seq.to(device)\n",
        "        target_seq = target_seq.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_seq, input_lengths, target_seq)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(output.view(-1, output_size), target_seq.view(-1))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the total loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print the average loss for the epoch\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
      ],
      "id": "184384eb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W7Mko_h8zSp"
      },
      "source": [
        "# Sequence to Sequence Translator"
      ],
      "id": "2W7Mko_h8zSp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4Qvk3C_85uY"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras.layers import TextVectorization\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "h4Qvk3C_85uY"
    },
    {
      "cell_type": "code",
      "source": [
        "eng_len = [len(sentence) for sentence in english_sentences]\n",
        "print(max(eng_len), min(eng_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0C9bAh4IAOO",
        "outputId": "8c4dfec0-340d-47f1-a39a-d5c8730f2620"
      },
      "id": "E0C9bAh4IAOO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7287 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "che_len = [len(sentence) for sentence in cherokee_sentences]\n",
        "print(max(che_len), min(che_len))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eGEDzWZIZRb",
        "outputId": "05ac5d50-5cdb-4efb-803a-bfe2a09b5212"
      },
      "id": "4eGEDzWZIZRb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4846 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8i3A5_Y9BwK",
        "outputId": "972d100c-83fa-4a75-bc1d-92b4c7ccafba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "107168 total pairs\n",
            "68587 training pairs\n",
            "17147 validation pairs\n",
            "21434 test pairs\n"
          ]
        }
      ],
      "source": [
        "# make text_pair and prepend the token \"[start]\" and postpend \"[end]\" to cherokee_sentences\n",
        "text_pair = []\n",
        "for i in range(len(english_sentences)):\n",
        "    text_pair.append([english_sentences[i], \"[start] \" + cherokee_sentences[i] + \" [end]\"])\n",
        "\n",
        "# split the sentence pairs into a training set, a validation set, and a test set.\n",
        "train_pairs, test_pairs = train_test_split(text_pair, test_size=0.2, random_state=42)\n",
        "train_pairs, val_pairs = train_test_split(train_pairs, test_size=0.2, random_state=42)\n",
        "print(f\"{len(text_pair)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "id": "p8i3A5_Y9BwK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IH-rYGXGGH8"
      },
      "source": [
        "## Vectorizing the text data\n",
        "\n",
        "use 2 TextVectorization layers to vectorize the text data (1 for English, 1 for Cherokee)"
      ],
      "id": "_IH-rYGXGGH8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDCYq37--JHD"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "strip_chars = string.punctuation\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = max(english_vocab_size, cherokee_vocab_size)\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    return tf_strings.regex_replace(input_string, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "che_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    # standardize=custom_standardization,\n",
        ")\n",
        "\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_che_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "che_vectorization.adapt(train_che_texts)"
      ],
      "id": "kDCYq37--JHD"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tmzqTif5J0ZF"
      },
      "id": "tmzqTif5J0ZF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage: transforming a single sentence\n",
        "sample_eng_sentence = train_eng_texts[0]\n",
        "sample_che_sentence = train_che_texts[0]\n",
        "\n",
        "# Applying the vectorization to the sample sentences\n",
        "eng_vectorized = eng_vectorization([sample_eng_sentence])\n",
        "che_vectorized = che_vectorization([sample_che_sentence])\n",
        "\n",
        "# Displaying the results\n",
        "print(sample_eng_sentence)\n",
        "print(\"English vectorized:\", eng_vectorized)\n",
        "print()\n",
        "print(sample_che_sentence)\n",
        "print(\"Chechen vectorized:\", che_vectorized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULMkn8qaJRJN",
        "outputId": "be293eb9-d491-4439-93cb-2bdcdf929bf3"
      },
      "id": "ULMkn8qaJRJN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And Simon himself had faith and, having had baptism, he went with Philip and, seeing the signs and the great wonders which he did, he was full of surprise.\n",
            "English vectorized: tf.Tensor(\n",
            "[[  3 425 137  50 140   3  73  50 737   9  55  22 741   3 360   2 566   3\n",
            "    2 114]], shape=(1, 20), dtype=int64)\n",
            "\n",
            "[start] ᏌᏩᏂᏃ ᎾᏍᏉ ᎤᏬᎯᏳᏁᎢ, ᎠᎦᏬᎥᏃ ᎤᏍᏓᏩᏗᏙᎴ ᏈᎵᎩ; ᎠᎪᏩᏗᏍᎬᏃ ᎤᏍᏆᏂᎪᏗ ᎠᎴ ᎤᏰᎸᏛ ᏚᎸᏫᏍᏓᏁᎲᎢ, ᎠᏍᏆᏂᎪᏍᎨᎢ. [end]\n",
            "Chechen vectorized: tf.Tensor(\n",
            "[[    2  1206    14 11149 24367 29106   572 30943   186     4   378   533\n",
            "  30644     3     0     0     0     0     0     0     0]], shape=(1, 21), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_q9d0hUGvlR"
      },
      "source": [
        "Now, format the datasets\n",
        "\n",
        "At each training step, the model will predict target word N + 1 using the source sentence and the target words 0 to N.\n",
        "\n",
        "Thus, the training dataset will yield (`inputs`, `targets`) where:\n",
        "* `inputs` - a dictionary with 2 keys:\n",
        "    - `encoder_inputs` - vectorized source sentence.\n",
        "    - `decoder_inputs` - the target sentence so far (words 0 to N used to predict the words 0 to N + 1)\n",
        "* `targets` - target sentence offset by 1 step - provides the next words in the target sentence — what the model will try to predict"
      ],
      "id": "L_q9d0hUGvlR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT7H8r4EGJPE"
      },
      "outputs": [],
      "source": [
        "def format_dataset(eng, che):\n",
        "    eng = eng_vectorization(eng)\n",
        "    che = che_vectorization(che)\n",
        "\n",
        "    inputs = {\n",
        "        \"encoder_inputs\": eng,\n",
        "        \"decoder_inputs\": che[:, :-1],\n",
        "    }\n",
        "\n",
        "    return (inputs, che[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    eng_texts, che_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    che_texts = list(che_texts)\n",
        "    dataset = tf_data.Dataset.from_tensor_slices((eng_texts, che_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.cache().shuffle(2048).prefetch(16)\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "id": "HT7H8r4EGJPE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8oNJPLuJelm",
        "outputId": "d5c4e2e6-becf-4b41-fe17-2ca5ece69bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "id": "x8oNJPLuJelm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0tF7sSlJl29"
      },
      "source": [
        "## Building the model:\n"
      ],
      "id": "H0tF7sSlJl29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3h9VoTLJyV8"
      },
      "source": [
        "Our sequence-to-sequence Transformer consists of a TransformerEncoder and a TransformerDecoder chained together. To make the model aware of word order, we also use a PositionalEmbedding layer.\n",
        "\n",
        "source sequence --> `TransformerEncoder` (output a new representation of the source) --> pass the new representation with the target sequence so far (target words 0 to N) to `TransformerDecoder` --> predict the next words in the target sequence (N + 1 and beyond)\n",
        "\n",
        "Layers adapted from https://keras.io/examples/nlp/neural_machine_translation_with_transformer/"
      ],
      "id": "h3h9VoTLJyV8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxtn1tDJKqnP"
      },
      "outputs": [],
      "source": [
        "import keras.ops as ops"
      ],
      "id": "qxtn1tDJKqnP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj74oiBjJjMw"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(dense_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"dense_dim\": self.dense_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "id": "fj74oiBjJjMw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MouDVIVK4q-"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(latent_dim, activation=\"relu\"),\n",
        "                layers.Dense(embed_dim),\n",
        "            ]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = ops.cast(mask[:, None, :], dtype=\"int32\")\n",
        "            padding_mask = ops.minimum(padding_mask, causal_mask)\n",
        "        else:\n",
        "            padding_mask = None\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = ops.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = ops.arange(sequence_length)[:, None]\n",
        "        j = ops.arange(sequence_length)\n",
        "        mask = ops.cast(i >= j, dtype=\"int32\")\n",
        "        mask = ops.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = ops.concatenate(\n",
        "            [ops.expand_dims(batch_size, -1), ops.convert_to_tensor([1, 1])],\n",
        "            axis=0,\n",
        "        )\n",
        "        return ops.tile(mask, mult)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"latent_dim\": self.latent_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ],
      "id": "4MouDVIVK4q-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pi_mpDsTKz0_"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = ops.shape(inputs)[-1]\n",
        "        positions = ops.arange(0, length, 1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        if mask is None:\n",
        "            return None\n",
        "        else:\n",
        "            return ops.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"sequence_length\": self.sequence_length,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config\n"
      ],
      "id": "Pi_mpDsTKz0_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OobIcMbNLBp-"
      },
      "source": [
        "Assemble the end-to-end model:"
      ],
      "id": "OobIcMbNLBp-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2oYgucPK7dh"
      },
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "id": "b2oYgucPK7dh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39C7a4PoLT5J"
      },
      "source": [
        "## Training our model"
      ],
      "id": "39C7a4PoLT5J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "GmRaoPbfLQ88",
        "outputId": "26a019c1-ebe1-4244-c8a7-8297e8f7e07a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"transformer\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │          \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ positional_embedding      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │ \u001b[38;5;34m18,631,424\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mPositionalEmbedding\u001b[0m)     │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ decoder_inputs            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │          \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ transformer_encoder       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │  \u001b[38;5;34m3,155,456\u001b[0m │ positional_embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)      │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ functional_5 (\u001b[38;5;33mFunctional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72759\u001b[0m)    │ \u001b[38;5;34m42,590,007\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│                           │                        │            │ transformer_encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ positional_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">18,631,424</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbedding</span>)     │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ decoder_inputs            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ transformer_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)      │                        │            │                            │\n",
              "├───────────────────────────┼────────────────────────┼────────────┼────────────────────────────┤\n",
              "│ functional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72759</span>)    │ <span style=\"color: #00af00; text-decoration-color: #00af00\">42,590,007</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│                           │                        │            │ transformer_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└───────────────────────────┴────────────────────────┴────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64,376,887\u001b[0m (245.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,376,887</span> (245.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m64,376,887\u001b[0m (245.58 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,376,887</span> (245.58 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 114ms/step - accuracy: 0.5970 - loss: 3.9345 - val_accuracy: 0.6393 - val_loss: 2.9544\n",
            "Epoch 2/3\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 99ms/step - accuracy: 0.6470 - loss: 2.8382 - val_accuracy: 0.6724 - val_loss: 2.4897\n",
            "Epoch 3/3\n",
            "\u001b[1m1072/1072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 98ms/step - accuracy: 0.6692 - loss: 2.5346 - val_accuracy: 0.6923 - val_loss: 2.2505\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f1fe00fbe50>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "epochs = 3  # 1 for testing\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
      ],
      "id": "GmRaoPbfLQ88"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model for later evaluation"
      ],
      "metadata": {
        "id": "NsJPzgdlq0Sf"
      },
      "id": "NsJPzgdlq0Sf"
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.save(\"sequence_to_sequence_3.keras\")"
      ],
      "metadata": {
        "id": "5V8VQD-1qzSO"
      },
      "id": "5V8VQD-1qzSO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcrT08UILl_O"
      },
      "source": [
        "## Decoding test sentences"
      ],
      "id": "GcrT08UILl_O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEdBAfZ9Ld8e"
      },
      "outputs": [],
      "source": [
        "che_vocab = che_vectorization.get_vocabulary()\n",
        "che_index_lookup = dict(zip(range(len(che_vocab)), che_vocab))\n",
        "max_decoded_sentence_length = 20\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = che_vectorization([decoded_sentence])[:, :-1]\n",
        "        # print(f\"tokenized_target_sentence: {tokenized_target_sentence}\")\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "        # ops.argmax(predictions[0, i, :]) is not a concrete value for jax here\n",
        "        sampled_token_index = ops.convert_to_numpy(\n",
        "            ops.argmax(predictions[0, i, :])\n",
        "        ).item(0)\n",
        "        # print(f\"sampled_token_index: {sampled_token_index}\")\n",
        "        sampled_token = che_index_lookup[sampled_token_index]\n",
        "        # print(sampled_token)\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence"
      ],
      "id": "fEdBAfZ9Ld8e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_inr8toXCuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ceed71-6cfa-4ec1-8d86-7e09c0ea4fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input      = This is a great secret: but my words are about Christ and the church.\n",
            "Translated = [start] ᎾᏍᎩ ᎢᏳᏍᏗ ᏞᏍᏗ ᎩᎶ ᏂᎯ ᎢᏤᎲ ᎤᏓᏑᏰᏍᏗ ᎤᏢᎨᏍᏗ ᏫᏓᏯᏂᏍᎨᏍᏗ ᏗᎨᎦᏗᎶᏗ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᎤᏁᎳᏅᎯ ᎤᏤᎵᎦ\n",
            "Input      = Just now went to be spelling.\n",
            "Translated = [start] ᎾᏍᎩ ᎢᏳᏍᏗ ᏞᏍᏗ ᎩᎶ ᏂᎯ ᎢᏤᎲ ᎤᏓᏑᏰᏍᏗ ᎤᏢᎨᏍᏗ ᏫᏓᏯᏂᏍᎨᏍᏗ ᏗᎨᎦᏗᎶᏗ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᎤᏁᎳᏅᎯ ᎤᏤᎵᎦ\n",
            "Input      = And Joseph, who was given by the Apostles the name of Barnabas (the sense of which is, Son of comfort), a Levite and a man of Cyprus by birth,\n",
            "Translated = [start] ᎾᏍᎩ ᎢᏳᏍᏗ ᏞᏍᏗ ᎩᎶ ᏂᎯ ᎢᏤᎲ ᎤᏓᏑᏰᏍᏗ ᎤᏢᎨᏍᏗ ᏫᏓᏯᏂᏍᎨᏍᏗ ᏗᎨᎦᏗᎶᏗ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᎤᏁᎳᏅᎯ ᎤᏤᎵᎦ\n",
            "Input      = But when they went on with their questions, he got up and said to them, Let him among you who is without sin be the first to send a stone at her.\n",
            "Translated = [start] ᎾᏍᎩ ᎢᏳᏍᏗ ᏞᏍᏗ ᎩᎶ ᏂᎯ ᎢᏤᎲ ᎤᏓᏑᏰᏍᏗ ᎤᏢᎨᏍᏗ ᏫᏓᏯᏂᏍᎨᏍᏗ ᏗᎨᎦᏗᎶᏗ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᎤᏁᎳᏅᎯ ᎤᏤᎵᎦ\n",
            "Input      = took it off a fire. fForanother\n",
            "Translated = [start] ᎾᏍᎩ ᎢᏳᏍᏗ ᏞᏍᏗ ᎩᎶ ᏂᎯ ᎢᏤᎲ ᎤᏓᏑᏰᏍᏗ ᎤᏢᎨᏍᏗ ᏫᏓᏯᏂᏍᎨᏍᏗ ᏗᎨᎦᏗᎶᏗ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᎤᏁᎳᏅᎯ ᎤᏤᎵᎦ\n",
            "Input      = And Jacob rose early in the morning, and took the stone that he had made his pillow, and set it up [for] a pillar, and poured oil on the top of it.\n",
            "Translated = [start] ᎾᏍᎩ ᎢᏳᏍᏗ ᏞᏍᏗ ᎩᎶ ᏂᎯ ᎢᏤᎲ ᎤᏓᏑᏰᏍᏗ ᎤᏢᎨᏍᏗ ᏫᏓᏯᏂᏍᎨᏍᏗ ᏗᎨᎦᏗᎶᏗ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᎤᏁᎳᏅᎯ ᎤᏤᎵᎦ\n",
            "Input      = And his fellow-servant fell down at his feet, and besought him, saying, Have patience with me, and I will pay thee all.\n",
            "Translated = [start] ᎾᏍᎩ ᎢᏳᏍᏗ ᏞᏍᏗ ᎩᎶ ᏂᎯ ᎢᏤᎲ ᎤᏓᏑᏰᏍᏗ ᎤᏢᎨᏍᏗ ᏫᏓᏯᏂᏍᎨᏍᏗ ᏗᎨᎦᏗᎶᏗ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᎤᏁᎳᏅᎯ ᎤᏤᎵᎦ\n",
            "Input      = Thus also my heavenly Father shall do to you if ye forgive not from your hearts every one his brother.\n",
            "Translated = [start] ᎾᏍᎩ ᎢᏳᏍᏗ ᏞᏍᏗ ᎩᎶ ᏂᎯ ᎢᏤᎲ ᎤᏓᏑᏰᏍᏗ ᎤᏢᎨᏍᏗ ᏫᏓᏯᏂᏍᎨᏍᏗ ᏗᎨᎦᏗᎶᏗ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᎤᏁᎳᏅᎯ ᎤᏤᎵᎦ\n",
            "Input      = Goes to be looking.\n",
            "Translated = [start] ᎾᏍᎩ ᎢᏳᏍᏗ ᏞᏍᏗ ᎩᎶ ᏂᎯ ᎢᏤᎲ ᎤᏓᏑᏰᏍᏗ ᎤᏢᎨᏍᏗ ᏫᏓᏯᏂᏍᎨᏍᏗ ᏗᎨᎦᏗᎶᏗ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᎤᏁᎳᏅᎯ ᎤᏤᎵᎦ\n",
            "Input      = Was ball-hooting.\n",
            "Translated = [start] ᎾᏍᎩ ᎢᏳᏍᏗ ᏞᏍᏗ ᎩᎶ ᏂᎯ ᎢᏤᎲ ᎤᏓᏑᏰᏍᏗ ᎤᏢᎨᏍᏗ ᏫᏓᏯᏂᏍᎨᏍᏗ ᏗᎨᎦᏗᎶᏗ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᏧᎾᏁᎶᏗ ᎤᎾᏓᏡᎬ ᎤᏁᎳᏅᎯ ᎤᏤᎵᎦ\n"
          ]
        }
      ],
      "source": [
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(10):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "\n",
        "    print(f\"Input      = {input_sentence}\\nTranslated = {translated}\")"
      ],
      "id": "K_inr8toXCuT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Future Directions"
      ],
      "metadata": {
        "id": "IxOxsDyD4lyU"
      },
      "id": "IxOxsDyD4lyU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "It may be interesting to compare the performances of English to Cherokee vs a Cherokee to English models.\n",
        "\n",
        "We'd also like to flush out the RNN and Encoder-Decoder approaches more in order to compare between other options for EnChr translation.\n",
        "\n",
        "A final avenue that we might pursue is comparing our output with that of an LLM translation and evaluating accuracy over all models."
      ],
      "metadata": {
        "id": "3hjtch6E4pgT"
      },
      "id": "3hjtch6E4pgT"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "abb883c7",
        "b2ccc858",
        "cfe00149",
        "578ea3d9"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}