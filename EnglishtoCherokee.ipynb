{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a5c282",
   "metadata": {},
   "source": [
    "# English to Cherokee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7b5ae",
   "metadata": {},
   "source": [
    "## Milestone Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df95152",
   "metadata": {},
   "source": [
    "### Team Members:\n",
    "Rithvik Doshi, Saisriram Gunturu, Ruihang (Henry) Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e4dec0",
   "metadata": {},
   "source": [
    "### Project Description\n",
    "\n",
    "We aim to create a model to translate English text to Cherokee. We're hoping to come up with an approach to this problem since Cherokee is an endangered language, and we can use the models we learned about in class specifically regarding machine translation to see how well we can do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba1ebd",
   "metadata": {},
   "source": [
    "### Approach\n",
    "We'll use the following data sources:\n",
    "- https://github.com/ZhangShiyue/ChrEn/tree/main/data\n",
    "- https://github.com/CherokeeLanguage/CherokeeEnglishCorpus/tree/master/corpus.aligned/en_chr\n",
    "\n",
    "Additionally, we will experiment with one of the following architectures/approaches to see what's the best way to translate from English to Cherokee:\n",
    "- https://github.com/lukysummer/Machine-Translation-Seq2Seq-Keras/tree/master/data\n",
    "- https://medium.com/@patrickhk/use-keras-to-build-a-english-to-french-translator-with-various-rnn-model-architecture-a374\n",
    "- https://github.com/LaurentVeyssier/Machine-translation-English-French-with-Deep-neural-Network/blob/main/machine_translation.ipynb\n",
    "- https://arxiv.org/pdf/2010.04791v1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04930484",
   "metadata": {},
   "source": [
    "### Project Plan:\n",
    "\n",
    "The project will consist of the following phases:\n",
    "1. EDA / Data Loading\n",
    "    a. Concatenating as many data sources as possible to get as big of a corpus as we can\n",
    "    b. Split data into training, testing and validation sets\n",
    "2. Model Developemnt\n",
    "    a. Finalize Model Selection and Architecture and build in Pytorch\n",
    "3. Model Training\n",
    "    a. Use available SCC GPUs to train the model.\n",
    "4. Model Validation\n",
    "    a. Validation sentences should give us a metric of accuracy.\n",
    "5. Model Testing\n",
    "    a. Use ChrEn model to translate back to English to see how we did."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b49d13",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716c4bbc",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c87acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy.random import shuffle, seed, choice\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split,Dataset,DataLoader,TensorDataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import nltk\n",
    "import pickle\n",
    "from statistics import mean\n",
    "from torchtext.vocab import GloVe\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6dae3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a336ea8",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a337165",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b548733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eng2chr",
   "language": "python",
   "name": "eng2chr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
